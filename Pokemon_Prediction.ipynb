{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDS Challenge: Starter Notebook\n",
    "\n",
    "This notebook will guide you through the first steps of the competition. Our goal here is to show you how to:\n",
    "\n",
    "1.  Load the `train.jsonl` and `test.jsonl` files from the competition data.\n",
    "2.  Create a very simple set of features from the data.\n",
    "3.  Train a basic model.\n",
    "4.  Generate a `submission.csv` file in the correct format.\n",
    "5.  Submit your results.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and Inspecting the Data\n",
    "\n",
    "When you create a notebook within a Kaggle competition, the competition's data is automatically attached and available in the `../input/` directory.\n",
    "\n",
    "The dataset is in a `.jsonl` format, which means each line is a separate JSON object. This is great because we can process it one line at a time without needing to load the entire large file into memory.\n",
    "\n",
    "Let's write a simple loop to load the training data and inspect the first battle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T13:34:56.379729Z",
     "iopub.status.busy": "2025-10-24T13:34:56.379445Z",
     "iopub.status.idle": "2025-10-24T13:35:11.460569Z",
     "shell.execute_reply": "2025-10-24T13:35:11.459324Z",
     "shell.execute_reply.started": "2025-10-24T13:34:56.379712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 'data\\train.jsonl'...\n",
      "Successfully loaded 10000 battles.\n",
      "\n",
      "--- Structure of the first train battle: ---\n",
      "{\n",
      "    \"player_won\": true,\n",
      "    \"p1_team_details\": [\n",
      "        {\n",
      "            \"name\": \"starmie\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"psychic\",\n",
      "                \"water\"\n",
      "            ],\n",
      "            \"base_hp\": 60,\n",
      "            \"base_atk\": 75,\n",
      "            \"base_def\": 85,\n",
      "            \"base_spa\": 100,\n",
      "            \"base_spd\": 100,\n",
      "            \"base_spe\": 115\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"exeggutor\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"grass\",\n",
      "                \"psychic\"\n",
      "            ],\n",
      "            \"base_hp\": 95,\n",
      "            \"base_atk\": 95,\n",
      "            \"base_def\": 85,\n",
      "            \"base_spa\": 125,\n",
      "            \"base_spd\": 125,\n",
      "            \"base_spe\": 55\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"chansey\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"normal\",\n",
      "                \"notype\"\n",
      "            ],\n",
      "            \"base_hp\": 250,\n",
      "            \"base_atk\": 5,\n",
      "            \"base_def\": 5,\n",
      "            \"base_spa\": 105,\n",
      "            \"base_spd\": 105,\n",
      "            \"base_spe\": 50\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"snorlax\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"normal\",\n",
      "                \"notype\"\n",
      "            ],\n",
      "            \"base_hp\": 160,\n",
      "            \"base_atk\": 110,\n",
      "            \"base_def\": 65,\n",
      "            \"base_spa\": 65,\n",
      "            \"base_spd\": 65,\n",
      "            \"base_spe\": 30\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"tauros\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"normal\",\n",
      "                \"notype\"\n",
      "            ],\n",
      "            \"base_hp\": 75,\n",
      "            \"base_atk\": 100,\n",
      "            \"base_def\": 95,\n",
      "            \"base_spa\": 70,\n",
      "            \"base_spd\": 70,\n",
      "            \"base_spe\": 110\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"alakazam\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"notype\",\n",
      "                \"psychic\"\n",
      "            ],\n",
      "            \"base_hp\": 55,\n",
      "            \"base_atk\": 50,\n",
      "            \"base_def\": 45,\n",
      "            \"base_spa\": 135,\n",
      "            \"base_spd\": 135,\n",
      "            \"base_spe\": 120\n",
      "        }\n",
      "    ],\n",
      "    \"p2_lead_details\": {\n",
      "        \"name\": \"starmie\",\n",
      "        \"level\": 100,\n",
      "        \"types\": [\n",
      "            \"psychic\",\n",
      "            \"water\"\n",
      "        ],\n",
      "        \"base_hp\": 60,\n",
      "        \"base_atk\": 75,\n",
      "        \"base_def\": 85,\n",
      "        \"base_spa\": 100,\n",
      "        \"base_spd\": 100,\n",
      "        \"base_spe\": 115\n",
      "    },\n",
      "    \"battle_timeline\": [\n",
      "        {\n",
      "            \"turn\": 1,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 1.0,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": {\n",
      "                \"name\": \"icebeam\",\n",
      "                \"type\": \"ICE\",\n",
      "                \"category\": \"SPECIAL\",\n",
      "                \"base_power\": 95,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            },\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"exeggutor\",\n",
      "                \"hp_pct\": 0.6895674300254453,\n",
      "                \"status\": \"frz\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": null\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 2,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"exeggutor\",\n",
      "                \"hp_pct\": 1.0,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": null,\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 1.0,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": null\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 3,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"exeggutor\",\n",
      "                \"hp_pct\": 0.22137404580152673,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": {\n",
      "                \"name\": \"sleeppowder\",\n",
      "                \"type\": \"GRASS\",\n",
      "                \"category\": \"STATUS\",\n",
      "                \"base_power\": 0,\n",
      "                \"accuracy\": 0.75,\n",
      "                \"priority\": 0\n",
      "            },\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 1.0,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": {\n",
      "                \"name\": \"blizzard\",\n",
      "                \"type\": \"ICE\",\n",
      "                \"category\": \"SPECIAL\",\n",
      "                \"base_power\": 120,\n",
      "                \"accuracy\": 0.9,\n",
      "                \"priority\": 0\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 4,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"chansey\",\n",
      "                \"hp_pct\": 0.8762446657183499,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": null,\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 1.0,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": {\n",
      "                \"name\": \"blizzard\",\n",
      "                \"type\": \"ICE\",\n",
      "                \"category\": \"SPECIAL\",\n",
      "                \"base_power\": 120,\n",
      "                \"accuracy\": 0.9,\n",
      "                \"priority\": 0\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 5,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"chansey\",\n",
      "                \"hp_pct\": 0.8762446657183499,\n",
      "                \"status\": \"par\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": {\n",
      "                \"name\": \"thunderbolt\",\n",
      "                \"type\": \"ELECTRIC\",\n",
      "                \"category\": \"SPECIAL\",\n",
      "                \"base_power\": 95,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            },\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 0.4953560371517028,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": {\n",
      "                \"name\": \"thunderwave\",\n",
      "                \"type\": \"ELECTRIC\",\n",
      "                \"category\": \"STATUS\",\n",
      "                \"base_power\": 0,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 6,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"chansey\",\n",
      "                \"hp_pct\": 0.8762446657183499,\n",
      "                \"status\": \"par\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": {\n",
      "                \"name\": \"thunderbolt\",\n",
      "                \"type\": \"ELECTRIC\",\n",
      "                \"category\": \"SPECIAL\",\n",
      "                \"base_power\": 95,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            },\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 0.08668730650154799,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": {\n",
      "                \"name\": \"recover\",\n",
      "                \"type\": \"NORMAL\",\n",
      "                \"category\": \"STATUS\",\n",
      "                \"base_power\": 0,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 7,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"chansey\",\n",
      "                \"hp_pct\": 0.8762446657183499,\n",
      "                \"status\": \"par\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": {\n",
      "                \"name\": \"thunderbolt\",\n",
      "                \"type\": \"ELECTRIC\",\n",
      "                \"category\": \"SPECIAL\",\n",
      "                \"base_power\": 95,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            },\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 0.5851393188854489,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": {\n",
      "                \"name\": \"recover\",\n",
      "                \"type\": \"NORMAL\",\n",
      "                \"category\": \"STATUS\",\n",
      "                \"base_power\": 0,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 8,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"chansey\",\n",
      "                \"hp_pct\": 0.8762446657183499,\n",
      "                \"status\": \"par\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": {\n",
      "                \"name\": \"thunderbolt\",\n",
      "                \"type\": \"ELECTRIC\",\n",
      "                \"category\": \"SPECIAL\",\n",
      "                \"base_power\": 95,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            },\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"snorlax\",\n",
      "                \"hp_pct\": 0.8011472275334608,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": null\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 9,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"snorlax\",\n",
      "                \"hp_pct\": 0.722753346080306,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": null,\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"snorlax\",\n",
      "                \"hp_pct\": 0.8011472275334608,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": {\n",
      "                \"name\": \"bodyslam\",\n",
      "                \"type\": \"NORMAL\",\n",
      "                \"category\": \"PHYSICAL\",\n",
      "                \"base_power\": 85,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 10,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"snorlax\",\n",
      "                \"hp_pct\": 0.21223709369024857,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"reflect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": {\n",
      "                \"name\": \"reflect\",\n",
      "                \"type\": \"PSYCHIC\",\n",
      "                \"category\": \"STATUS\",\n",
      "                \"base_power\": 0,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            },\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"snorlax\",\n",
      "                \"hp_pct\": 0.8011472275334608,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": {\n",
      "                \"name\": \"bodyslam\",\n",
      "                \"type\": \"NORMAL\",\n",
      "                \"category\": \"PHYSICAL\",\n",
      "                \"base_power\": 85,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"battle_id\": 0\n",
      "}\n",
      "    ...\n",
      "    (battle_timeline has been truncated for display)\n",
      "\n",
      "Processing test data...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Define the path to our data ---\n",
    "train_file_path = os.path.join(\"data\", 'train.jsonl')\n",
    "test_file_path = os.path.join(\"data\", 'test.jsonl')\n",
    "train_data = []\n",
    "\n",
    "# Read the file line by line\n",
    "print(f\"Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # json.loads() parses one line (one JSON object) into a Python dictionary\n",
    "            train_data.append(json.loads(line))\n",
    "\n",
    "    print(f\"Successfully loaded {len(train_data)} battles.\")\n",
    "\n",
    "    # Let's inspect the first battle to see its structure\n",
    "    print(\"\\n--- Structure of the first train battle: ---\")\n",
    "    if train_data:\n",
    "        first_battle = train_data[0]\n",
    "        \n",
    "        # To keep the output clean, we can create a copy and truncate the timeline\n",
    "        battle_for_display = first_battle.copy()\n",
    "        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])[:10] # Show first 2 turns\n",
    "        \n",
    "        # Use json.dumps for pretty-printing the dictionary\n",
    "        print(json.dumps(battle_for_display, indent=4))\n",
    "        if len(first_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Feature Engineering\n",
    "\n",
    "A successful model will likely require creating many complex features. For this starter notebook, however, we will create a very simple feature set based **only on the initial team stats**. This will be enough to train a model and generate a submission file.\n",
    "\n",
    "It's up to you to engineer more powerful features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§© Alle Typen:\n",
      "['dragon', 'electric', 'fire', 'flying', 'ghost', 'grass', 'ground', 'ice', 'normal', 'poison', 'psychic', 'rock', 'water']\n",
      "\n",
      "ðŸ“Š PokÃ©mon DataFrame:\n",
      "          name               types  base_hp  base_atk  base_def  base_spa  \\\n",
      "0      starmie    [psychic, water]       60        75        85       100   \n",
      "1    exeggutor    [grass, psychic]       95        95        85       125   \n",
      "2      chansey    [normal, notype]      250         5         5       105   \n",
      "3      snorlax    [normal, notype]      160       110        65        65   \n",
      "4       tauros    [normal, notype]       75       100        95        70   \n",
      "5     alakazam   [notype, psychic]       55        50        45       135   \n",
      "6         jynx      [ice, psychic]       65        50        35        95   \n",
      "7      slowbro    [psychic, water]       95        75       110        80   \n",
      "8       gengar     [ghost, poison]       60        65        60       130   \n",
      "9       rhydon      [ground, rock]      105       130       120        45   \n",
      "10      zapdos  [electric, flying]       90        90        85       125   \n",
      "11    cloyster        [ice, water]       50        95       180        85   \n",
      "12       golem      [ground, rock]       80       110       130        55   \n",
      "13     jolteon  [electric, notype]       65        65        60       110   \n",
      "14    articuno       [flying, ice]       90        85       100       125   \n",
      "15     persian    [normal, notype]       65        70        60        65   \n",
      "16      lapras        [ice, water]      130        85        80        95   \n",
      "17   dragonite    [dragon, flying]       91       134        95       100   \n",
      "18  victreebel     [grass, poison]       80       105        65       100   \n",
      "19   charizard      [fire, flying]       78        84        78        85   \n",
      "\n",
      "    base_spd  base_spe  \n",
      "0        100       115  \n",
      "1        125        55  \n",
      "2        105        50  \n",
      "3         65        30  \n",
      "4         70       110  \n",
      "5        135       120  \n",
      "6         95        95  \n",
      "7         80        30  \n",
      "8        130       110  \n",
      "9         45        40  \n",
      "10       125       100  \n",
      "11        85        70  \n",
      "12        55        45  \n",
      "13       110       130  \n",
      "14       125        85  \n",
      "15        65       115  \n",
      "16        95        60  \n",
      "17       100        80  \n",
      "18       100        70  \n",
      "19        85       100  \n"
     ]
    }
   ],
   "source": [
    "def extract_pokemon_and_types(battles):\n",
    "    all_pokemon = []\n",
    "    all_types = set()\n",
    "\n",
    "    for battle in battles:\n",
    "        # Team PokÃ©mon\n",
    "        for p in battle[\"p1_team_details\"]:\n",
    "            all_pokemon.append({\n",
    "                \"name\": p[\"name\"].lower(),\n",
    "                \"types\": p[\"types\"],\n",
    "                \"base_hp\": p[\"base_hp\"],\n",
    "                \"base_atk\": p[\"base_atk\"],\n",
    "                \"base_def\": p[\"base_def\"],\n",
    "                \"base_spa\": p[\"base_spa\"],\n",
    "                \"base_spd\": p[\"base_spd\"],\n",
    "                \"base_spe\": p[\"base_spe\"],\n",
    "            })\n",
    "            all_types.update([t for t in p[\"types\"] if t != \"notype\"])\n",
    "        enemy_pokemon = battle[\"p2_lead_details\"]\n",
    "        all_pokemon.append({\n",
    "                \"name\": enemy_pokemon[\"name\"].lower(),\n",
    "                \"types\": enemy_pokemon[\"types\"],\n",
    "                \"base_hp\": enemy_pokemon[\"base_hp\"],\n",
    "                \"base_atk\": enemy_pokemon[\"base_atk\"],\n",
    "                \"base_def\": enemy_pokemon[\"base_def\"],\n",
    "                \"base_spa\": enemy_pokemon[\"base_spa\"],\n",
    "                \"base_spd\": enemy_pokemon[\"base_spd\"],\n",
    "                \"base_spe\": enemy_pokemon[\"base_spe\"],\n",
    "            })\n",
    "        all_types.update([t for t in enemy_pokemon[\"types\"] if t != \"notype\"])\n",
    "    # Als DataFrame, Duplikate entfernen\n",
    "    pokemon_df = pd.DataFrame(all_pokemon).drop_duplicates(subset=\"name\").reset_index(drop=True)\n",
    "    types_list = sorted(list(all_types))\n",
    "\n",
    "    return pokemon_df, types_list\n",
    "\n",
    "\n",
    "# Beispiel:\n",
    "pokemon_df, all_types = extract_pokemon_and_types(train_data)\n",
    "\n",
    "print(\"ðŸ§© Alle Typen:\")\n",
    "print(all_types)\n",
    "print(\"\\nðŸ“Š PokÃ©mon DataFrame:\")\n",
    "print(pokemon_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute the type advantage and stat advantage out of the pokemons the enemy has and player 1 has\n",
    "import numpy as np\n",
    "\n",
    "# simplified Gen 1 type chart\n",
    "type_chart = {\n",
    "    \"normal\":    {\"rock\": 0.5, \"ghost\": 0.0},\n",
    "    \"fire\":      {\"fire\": 0.5, \"water\": 0.5, \"grass\": 2, \"ice\": 2, \"bug\": 2, \"rock\": 0.5, \"dragon\": 0.5},\n",
    "    \"water\":     {\"fire\": 2, \"water\": 0.5, \"grass\": 0.5, \"ground\": 2, \"rock\": 2, \"dragon\": 0.5},\n",
    "    \"electric\":  {\"water\": 2, \"electric\": 0.5, \"grass\": 0.5, \"ground\": 0, \"flying\": 2, \"dragon\": 0.5},\n",
    "    \"grass\":     {\"fire\": 0.5, \"water\": 2, \"grass\": 0.5, \"poison\": 0.5, \"ground\": 2, \"flying\": 0.5, \"rock\": 2},\n",
    "    \"ice\":       {\"water\": 0.5, \"grass\": 2, \"ice\": 0.5, \"ground\": 2, \"flying\": 2, \"dragon\": 2},\n",
    "    \"fighting\":  {\"normal\": 2, \"ice\": 2, \"rock\": 2, \"ghost\": 0, \"psychic\": 0.5},\n",
    "    \"poison\":    {\"grass\": 2, \"poison\": 0.5, \"ground\": 0.5, \"rock\": 0.5, \"ghost\": 0.5},\n",
    "    \"ground\":    {\"fire\": 2, \"electric\": 2, \"grass\": 0.5, \"poison\": 2, \"flying\": 0, \"rock\": 2},\n",
    "    \"flying\":    {\"electric\": 0.5, \"grass\": 2, \"fighting\": 2, \"bug\": 2, \"rock\": 0.5},\n",
    "    \"psychic\":   {\"fighting\": 2, \"poison\": 2, \"psychic\": 0.5},\n",
    "    \"bug\":       {\"fire\": 0.5, \"grass\": 2, \"fighting\": 0.5, \"poison\": 2, \"flying\": 0.5, \"psychic\": 2},\n",
    "    \"rock\":      {\"fire\": 2, \"ice\": 2, \"fighting\": 0.5, \"ground\": 0.5, \"flying\": 2, \"bug\": 2},\n",
    "    \"ghost\":     {\"normal\": 0, \"psychic\": 0},\n",
    "    \"dragon\":    {\"dragon\": 2},\n",
    "    \"notype\":    {}\n",
    "}\n",
    "\n",
    "def compute_type_advantage(p1_types, p2_types, chart):\n",
    "    multipliers = []\n",
    "    for atk_type in p1_types:\n",
    "        for def_type in p2_types:\n",
    "            if atk_type in chart:\n",
    "                mult = chart[atk_type].get(def_type, 1.0)\n",
    "            else:\n",
    "                mult = 1.0\n",
    "            multipliers.append(mult)\n",
    "    if not multipliers:\n",
    "        return 1.0\n",
    "    return np.mean(multipliers)\n",
    "\n",
    "def compute_type_and_stat_advantages(battles, pokemon_df, all_types):\n",
    "    type_advantages = []\n",
    "    stat_advantages = []\n",
    "\n",
    "    type_to_index = {t: i for i, t in enumerate(all_types)}\n",
    "\n",
    "    for battle in battles:\n",
    "        p1_pokemon = []\n",
    "        for p in battle[\"p1_team_details\"]:\n",
    "            p1_pokemon.append(p[\"name\"].lower())\n",
    "        # get all pokemon the enemy has\n",
    "        enemy_pokemon = [battle[\"p2_lead_details\"]['name']]\n",
    "        for turn in battle[\"battle_timeline\"]:\n",
    "            e_p = turn['p2_pokemon_state']['name']\n",
    "            if e_p.lower() not in enemy_pokemon:\n",
    "                enemy_pokemon.append(e_p.lower())\n",
    "        \n",
    "        p1_types = []\n",
    "        p1_stats = []\n",
    "        for p_name in p1_pokemon:\n",
    "            p_data = pokemon_df[pokemon_df['name'] == p_name].iloc[0]\n",
    "            p1_types.append(p_data['types'])\n",
    "            p1_stats.append([\n",
    "                p_data['base_hp'],\n",
    "                p_data['base_atk'],\n",
    "                p_data['base_def'],\n",
    "                p_data['base_spa'],\n",
    "                p_data['base_spd'],\n",
    "                p_data['base_spe'],\n",
    "            ])\n",
    "        enemy_types = []\n",
    "        enemy_stats = []\n",
    "        for e_name in enemy_pokemon:\n",
    "            e_data = pokemon_df[pokemon_df['name'] == e_name].iloc[0]\n",
    "            enemy_types.append(e_data['types'])\n",
    "            enemy_stats.append([\n",
    "                e_data['base_hp'],\n",
    "                e_data['base_atk'],\n",
    "                e_data['base_def'],\n",
    "                e_data['base_spa'],\n",
    "                e_data['base_spd'],\n",
    "                e_data['base_spe'],\n",
    "            ])\n",
    "        #print(p1_pokemon, enemy_pokemon)\n",
    "        #print(p1_types, enemy_types)\n",
    "        #print(p1_stats, enemy_stats)\n",
    "        \n",
    "        # now compute the type advantage and stat advantage\n",
    "        # flatten type lists, remove \"notype\"\n",
    "        p1_all_types = [t for ts in p1_types for t in ts if t != \"notype\"]\n",
    "        p2_all_types = [t for ts in enemy_types for t in ts if t != \"notype\"]\n",
    "        # team vs team type advantage\n",
    "        p1_type_adv = compute_type_advantage(p1_all_types, p2_all_types, type_chart)\n",
    "        p2_type_adv = compute_type_advantage(p2_all_types, p1_all_types, type_chart)\n",
    "\n",
    "        type_advantage = p1_type_adv / p2_type_adv\n",
    "        \n",
    "        # convert to numpy arrays\n",
    "        p1_stats = np.array(p1_stats, dtype=float)\n",
    "        p2_stats = np.array(enemy_stats, dtype=float)\n",
    "\n",
    "        # compute mean overall stat\n",
    "        p1_avg = p1_stats.mean()\n",
    "        p2_avg = p2_stats.mean()\n",
    "\n",
    "        stat_advantage = p1_avg / p2_avg\n",
    "\n",
    "        type_advantages.append(type_advantage)\n",
    "        stat_advantages.append(stat_advantage)\n",
    "\n",
    "    return type_advantages, stat_advantages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T13:39:31.524020Z",
     "iopub.status.busy": "2025-10-24T13:39:31.523388Z",
     "iopub.status.idle": "2025-10-24T13:39:38.597940Z",
     "shell.execute_reply": "2025-10-24T13:39:38.596425Z",
     "shell.execute_reply.started": "2025-10-24T13:39:31.523762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb1e59239684edab5c7747628223087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab70a581bcce4464b55e8211a702d96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training features preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_mean_hp</th>\n",
       "      <th>p1_mean_spe</th>\n",
       "      <th>p1_mean_atk</th>\n",
       "      <th>p1_mean_def</th>\n",
       "      <th>p1_mean_spa</th>\n",
       "      <th>p1_mean_spd</th>\n",
       "      <th>p2_lead_hp</th>\n",
       "      <th>p2_lead_spe</th>\n",
       "      <th>p2_lead_atk</th>\n",
       "      <th>p2_lead_def</th>\n",
       "      <th>p2_lead_spa</th>\n",
       "      <th>p2_lead_spd</th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115.833333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>115</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>65.833333</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124.166667</td>\n",
       "      <td>65.833333</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>71.666667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>250</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121.666667</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>65.833333</td>\n",
       "      <td>103.333333</td>\n",
       "      <td>103.333333</td>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.166667</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>60</td>\n",
       "      <td>115</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1_mean_hp  p1_mean_spe  p1_mean_atk  p1_mean_def  p1_mean_spa  \\\n",
       "0  115.833333    80.000000    72.500000    63.333333   100.000000   \n",
       "1  123.333333    61.666667    72.500000    65.833333    90.000000   \n",
       "2  124.166667    65.833333    84.166667    71.666667    90.000000   \n",
       "3  121.666667    75.833333    77.500000    65.833333   103.333333   \n",
       "4  114.166667    72.500000    75.833333    79.166667    97.500000   \n",
       "\n",
       "   p1_mean_spd  p2_lead_hp  p2_lead_spe  p2_lead_atk  p2_lead_def  \\\n",
       "0   100.000000          60          115           75           85   \n",
       "1    90.000000          55          120           50           45   \n",
       "2    90.000000         250           50            5            5   \n",
       "3   103.333333          75          110          100           95   \n",
       "4    97.500000          60          115           75           85   \n",
       "\n",
       "   p2_lead_spa  p2_lead_spd  battle_id  player_won  \n",
       "0          100          100          0           1  \n",
       "1          135          135          1           1  \n",
       "2          105          105          2           1  \n",
       "3           70           70          3           1  \n",
       "4          100          100          4           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def create_simple_features(data: list[dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A very basic feature extraction function.\n",
    "    It only uses the aggregated base stats of the player's team and opponent's lead.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    for battle in tqdm(data, desc=\"Extracting features\"):\n",
    "        features = {}\n",
    "        \n",
    "        # --- Player 1 Team Features ---\n",
    "        p1_team = battle.get('p1_team_details', [])\n",
    "        if p1_team:\n",
    "            features['p1_mean_hp'] = np.mean([p.get('base_hp', 0) for p in p1_team])\n",
    "            features['p1_mean_spe'] = np.mean([p.get('base_spe', 0) for p in p1_team])\n",
    "            features['p1_mean_atk'] = np.mean([p.get('base_atk', 0) for p in p1_team])\n",
    "            features['p1_mean_def'] = np.mean([p.get('base_def', 0) for p in p1_team])\n",
    "            features['p1_mean_spa'] = np.mean([p.get('base_spa', 0) for p in p1_team])\n",
    "            features['p1_mean_spd'] = np.mean([p.get('base_spd', 0) for p in p1_team])\n",
    "        # --- Player 2 Lead Features ---\n",
    "        p2_lead = battle.get('p2_lead_details')\n",
    "        if p2_lead:\n",
    "            # Player 2's lead PokÃ©mon's stats\n",
    "            features['p2_lead_hp'] = p2_lead.get('base_hp', 0)\n",
    "            features['p2_lead_spe'] = p2_lead.get('base_spe', 0)\n",
    "            features['p2_lead_atk'] = p2_lead.get('base_atk', 0)\n",
    "            features['p2_lead_def'] = p2_lead.get('base_def', 0)\n",
    "            features['p2_lead_spa'] = p2_lead.get('base_spa', 0)\n",
    "            features['p2_lead_spd'] = p2_lead.get('base_spd', 0)\n",
    "\n",
    "        # We also need the ID and the target variable (if it exists)\n",
    "        features['battle_id'] = battle.get('battle_id')\n",
    "        if 'player_won' in battle:\n",
    "            features['player_won'] = int(battle['player_won'])\n",
    "            \n",
    "        feature_list.append(features)\n",
    "        \n",
    "    return pd.DataFrame(feature_list).fillna(0)\n",
    "\n",
    "# Create feature DataFrames for both training and test sets\n",
    "print(\"Processing training data...\")\n",
    "train_df = create_simple_features(train_data)\n",
    "\n",
    "test_df = create_simple_features(test_data)\n",
    "\n",
    "print(\"\\nTraining features preview:\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dynamic Features out of the battle timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05b9022c6ee4a0396fa4807b58a81a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting two-dict features:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\962436815.py:265: RuntimeWarning: Mean of empty slice.\n",
      "  p1_avg = p1_stats.mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a7d96823c74d278d5f87aba5ea5821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting two-dict features:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training features preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>hp_ratio</th>\n",
       "      <th>p1_num_seen</th>\n",
       "      <th>p2_num_seen</th>\n",
       "      <th>p1_num_fainted</th>\n",
       "      <th>p2_num_fainted</th>\n",
       "      <th>num_paralyzed_diff</th>\n",
       "      <th>num_frozen_diff</th>\n",
       "      <th>num_psn_diff</th>\n",
       "      <th>num_brn_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>num_seen_diff</th>\n",
       "      <th>num_fainted_diff</th>\n",
       "      <th>type_advantage</th>\n",
       "      <th>stat_advantage</th>\n",
       "      <th>boost_advantage</th>\n",
       "      <th>stall_move_usage_diff</th>\n",
       "      <th>boost_move_usage_diff</th>\n",
       "      <th>switch_frequency_diff</th>\n",
       "      <th>num_setup_diff</th>\n",
       "      <th>has_recovery_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.892367</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.614786</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.946708</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.209302</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>1.032558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.283721</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.046875</td>\n",
       "      <td>1.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  hp_ratio  p1_num_seen  p2_num_seen  p1_num_fainted  \\\n",
       "0          0  2.892367            4            4               1   \n",
       "1          1  0.614786            6            6               3   \n",
       "2          2  0.546296            3            4               1   \n",
       "3          3  1.209302            5            4               3   \n",
       "4          4  1.283721            5            5               1   \n",
       "\n",
       "   p2_num_fainted  num_paralyzed_diff  num_frozen_diff  num_psn_diff  \\\n",
       "0               1                   0               -1             0   \n",
       "1               0                  -2                0             0   \n",
       "2               0                  -1                0             0   \n",
       "3               0                   0                0             0   \n",
       "4               0                  -2                0             0   \n",
       "\n",
       "   num_brn_diff  ...  num_seen_diff  num_fainted_diff  type_advantage  \\\n",
       "0             0  ...              0                 0        0.923077   \n",
       "1             0  ...              0                 3        0.951613   \n",
       "2             0  ...             -1                 1        1.000000   \n",
       "3             0  ...              1                 3        1.057143   \n",
       "4             0  ...              0                 1        1.046875   \n",
       "\n",
       "   stat_advantage  boost_advantage  stall_move_usage_diff  \\\n",
       "0        0.962733         0.000000                      7   \n",
       "1        0.946708         0.066667                     -2   \n",
       "2        0.950820         0.100000                     -2   \n",
       "3        1.032558         0.000000                      3   \n",
       "4        1.018868         0.000000                     -6   \n",
       "\n",
       "   boost_move_usage_diff  switch_frequency_diff  num_setup_diff  \\\n",
       "0                      0                     -4               0   \n",
       "1                      0                      0               0   \n",
       "2                      8                      2               1   \n",
       "3                      0                      1               0   \n",
       "4                      0                     -2               0   \n",
       "\n",
       "   has_recovery_diff  \n",
       "0                 -1  \n",
       "1                  0  \n",
       "2                 -1  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# has recovery move\n",
    "\n",
    "STALL_MOVES = {\n",
    "    # healing\n",
    "    \"recover\", \"softboiled\", \"rest\",\n",
    "\n",
    "    # defensive buffs / shields\n",
    "    \"lightscreen\", \"reflect\", \"substitute\",\n",
    "\n",
    "    # passive damage / tempo control\n",
    "    \"toxic\", \"leechseed\",\n",
    "\n",
    "    # status spreading\n",
    "    \"thunderwave\", \"stunspore\", \"poisonpowder\",\n",
    "    \"sleeppowder\", \"sing\", \"hypnosis\",\n",
    "\n",
    "    # accuracy / confusion stall\n",
    "    \"confuseray\", \"supersonic\",\n",
    "    \"flash\", \"kinesis\", \"smokescreen\", \"sandattack\",\n",
    "\n",
    "    # utility disruption\n",
    "    \"disable\"\n",
    "}\n",
    "\n",
    "def get_sum_stall_moves(timeline, player_prefix=\"p1\"):\n",
    "    stall_move_count = 0\n",
    "\n",
    "    for turn in timeline:\n",
    "        move_details = turn.get(f\"{player_prefix}_move_details\")\n",
    "        if move_details and move_details[\"name\"].lower() in STALL_MOVES:\n",
    "            stall_move_count += 1\n",
    "\n",
    "    return stall_move_count\n",
    "\n",
    "BOOST_MOVES = {\n",
    "    \"swordsdance\", \"meditate\", \"sharpen\",\n",
    "    \"amnesia\", \"growth\",\n",
    "    \"agility\",\n",
    "    \"harden\", \"defensecurl\", \"barrier\", \"acidarmor\",\n",
    "    \"doubleteam\", \"minimize\"\n",
    "}\n",
    "\n",
    "def get_sum_boost_moves(timeline, player_prefix=\"p1\"):\n",
    "    boost_move_count = 0\n",
    "\n",
    "    for turn in timeline:\n",
    "        move_details = turn.get(f\"{player_prefix}_move_details\")\n",
    "        if move_details and move_details[\"name\"].lower() in BOOST_MOVES:\n",
    "            boost_move_count += 1\n",
    "\n",
    "    return boost_move_count\n",
    "\n",
    "def get_number_of_switches(timeline, player_prefix=\"p1\"):\n",
    "    switch_count = 0\n",
    "\n",
    "    previous_pokemon = None\n",
    "    for turn in timeline:\n",
    "        state = turn.get(f\"{player_prefix}_pokemon_state\", {})\n",
    "        if not state or \"name\" not in state:\n",
    "            continue\n",
    "\n",
    "        current_pokemon = state[\"name\"]\n",
    "        if previous_pokemon is not None and current_pokemon != previous_pokemon:\n",
    "            switch_count += 1\n",
    "        previous_pokemon = current_pokemon\n",
    "\n",
    "    return switch_count\n",
    "\n",
    "SETUP_POKEMON = {\n",
    "    # Amnesia users\n",
    "    \"slowbro\", \"snorlax\", \"mewtwo\", \"mew\",\n",
    "    \n",
    "    # Swords Dance users\n",
    "    \"pinsir\", \"kingler\", \"scyther\", \"sandslash\", \"mew\",\n",
    "    \n",
    "    # Growth users\n",
    "    \"victreebel\", \"venusaur\", \"tangela\",\n",
    "    \n",
    "    # Agility sweepers\n",
    "    \"jolteon\", \"zapdos\", \"dragonite\", \"fearow\",\n",
    "    \n",
    "    # Barrier / Acid Armor\n",
    "    \"mrmime\", \"dewgong\", \"muk\", \"vaporeon\", \"mewtwo\",\n",
    "}\n",
    "\n",
    "def get_setup_pokemon(pokemon_dict):\n",
    "    setup_users = []\n",
    "\n",
    "    for pokemon, values in pokemon_dict.items():\n",
    "        moves = values.get(\"moves\", [])\n",
    "        for m in moves:\n",
    "            normalized = m.lower().replace(\" \", \"\")\n",
    "            if normalized in BOOST_MOVES:\n",
    "                setup_users.append(pokemon)\n",
    "                break  # no need to check more moves\n",
    "\n",
    "    return setup_users\n",
    "\n",
    "def num_setup(pokemon_dict):\n",
    "    return len(get_setup_pokemon(pokemon_dict))\n",
    "\n",
    "def build_player_dict(timeline, prefix):\n",
    "    player_pokemons = {}\n",
    "\n",
    "    for turn in timeline:\n",
    "        state = turn.get(f\"{prefix}_pokemon_state\", {})\n",
    "        if not state or \"name\" not in state:\n",
    "            continue\n",
    "\n",
    "        name = state[\"name\"]\n",
    "        if name not in player_pokemons:\n",
    "            player_pokemons[name] = {\n",
    "                \"hp\": 1,\n",
    "                \"status\": \"\",\n",
    "                \"moves\": [],\n",
    "                \"boosts\": {k: [] for k in [\"atk\", \"def\", \"spa\", \"spd\", \"spe\"]}            }\n",
    "\n",
    "        # HP and status\n",
    "        player_pokemons[name][\"hp\"] = state.get(\"hp_pct\", 0)\n",
    "        player_pokemons[name][\"status\"] = state[\"status\"]\n",
    "\n",
    "        # Boosts\n",
    "        boosts = state.get(\"boosts\", {})\n",
    "        for k in player_pokemons[name][\"boosts\"]:\n",
    "            player_pokemons[name][\"boosts\"][k] = boosts.get(k, 0)\n",
    "\n",
    "        # Moves used\n",
    "        move_details = turn.get(f\"{prefix}_move_details\")\n",
    "        if move_details != None:\n",
    "            if move_details['name'] not in player_pokemons[name][\"moves\"]:\n",
    "                player_pokemons[name][\"moves\"].append(move_details[\"name\"])\n",
    "\n",
    "    # Summarize per PokÃ©mon\n",
    "    return player_pokemons\n",
    "\n",
    "\n",
    "def aggregate_player_stats(player_dict):\n",
    "    \"\"\"Aggregates all PokÃ©mon stats for one player.\"\"\"\n",
    "    if not player_dict:\n",
    "        return {\n",
    "            \"mean_hp\": 0,\n",
    "            \"total_hp_left\": 0,\n",
    "            \"num_seen\": 0,\n",
    "            \"num_fainted\": 0,\n",
    "            \"avg_boosts\": {k: 0 for k in [\"atk\", \"def\", \"spa\", \"spd\", \"spe\"]},\n",
    "            \"status_freq\": {s: 0 for s in [\"par\", \"frz\", \"psn\", \"brn\", \"slp\"]},\n",
    "            \"types\": [],\n",
    "        }\n",
    "\n",
    "    pokemons_names = player_dict.keys()\n",
    "    pokemons = list(player_dict.values())\n",
    "    num_fainted = sum(1 for pokemon in pokemons if pokemon['status'] == \"fnt\")\n",
    "    \n",
    "    # return the pokemon left\n",
    "    pokemon_left = [name for name, p in zip(pokemons_names, pokemons) if p['status'] != \"fnt\"]\n",
    "    pokemon_left_stats = [p for name, p in zip(pokemons_names, pokemons) if p['status'] != \"fnt\"]\n",
    "    total_hp_left = sum(p[\"hp\"] for p in pokemon_left_stats)\n",
    "    status_counts = Counter(p['status'] for p in pokemon_left_stats if p.get('status'))\n",
    "    num_paralyzed = status_counts['par']\n",
    "    num_frozen = status_counts['frz']\n",
    "    num_psn = status_counts['psn']\n",
    "    num_brn = status_counts['brn']\n",
    "    num_slp = status_counts['slp']\n",
    "    boosts = {k: np.mean([p[\"boosts\"][k] for p in pokemon_left_stats]) for k in [\"atk\", \"def\", \"spa\", \"spd\", \"spe\"]}\n",
    "    #print(\"Boosts:\", boosts)\n",
    "\n",
    "    return {\n",
    "        \"total_hp_left\": total_hp_left,\n",
    "        \"num_seen\": len(pokemons),\n",
    "        \"num_fainted\": num_fainted,\n",
    "        \"num_paralyzed\": num_paralyzed,\n",
    "        \"num_frozen\": num_frozen,\n",
    "        \"num_psn\": num_psn,\n",
    "        \"num_brn\": num_brn,\n",
    "        \"num_slp\": num_slp,\n",
    "        \"avg_boosts\": boosts,\n",
    "    }, pokemon_left\n",
    "\n",
    "\n",
    "def create_dynamic_features(data: list[dict]) -> pd.DataFrame:\n",
    "    feature_list = []\n",
    "\n",
    "    for battle in tqdm(data, desc=\"Extracting two-dict features\"):\n",
    "        timeline = battle.get(\"battle_timeline\", [])\n",
    "        if not timeline:\n",
    "            continue\n",
    "\n",
    "        p1_dict = build_player_dict(timeline, \"p1\")\n",
    "        p2_dict = build_player_dict(timeline, \"p2\")\n",
    "        #print(\"Player 1 dict:\", p1_dict, \"\\n\")\n",
    "        #print(\"Player 2 dict:\", p2_dict, \"\\n\")\n",
    "        p1_stats, p1_pokemon_left = aggregate_player_stats(p1_dict)\n",
    "        p2_stats, p2_pokemon_left = aggregate_player_stats(p2_dict)\n",
    "\n",
    "        n_stall_moves_p1 = get_sum_stall_moves(timeline)\n",
    "        n_stall_moves_p2 = get_sum_stall_moves(timeline, player_prefix=\"p2\")\n",
    "        \n",
    "        stall_move_usage_diff = n_stall_moves_p1 - n_stall_moves_p2\n",
    "\n",
    "        n_boost_moves_p1 = get_sum_boost_moves(timeline)\n",
    "        n_boost_moves_p2 = get_sum_boost_moves(timeline, player_prefix=\"p2\")\n",
    "\n",
    "        boost_move_usage_diff = n_boost_moves_p1 - n_boost_moves_p2\n",
    "\n",
    "        n_switches_p1 = get_number_of_switches(timeline)\n",
    "        n_switches_p2 = get_number_of_switches(timeline, player_prefix=\"p2\")\n",
    "        switch_frequency_diff = n_switches_p1 - n_switches_p2\n",
    "        \n",
    "        num_setup_p1 = num_setup(p1_dict)\n",
    "        num_setup_p2 = num_setup(p2_dict)\n",
    "        num_setup_diff = num_setup_p1 - num_setup_p2\n",
    "\n",
    "        has_recovery_p1 = any(move.lower() == 'recover' for p in p1_dict.values() for move in p['moves'])\n",
    "        has_recovery_p2 = any(move.lower() == 'recover' for p in p2_dict.values() for move in p['moves'])\n",
    "        has_recovery_diff = has_recovery_p1 - has_recovery_p2\n",
    "\n",
    "        def type_and_stat_advantages(p1_pokemon_left, p2_pokemon_left, pokemon_df, all_types):\n",
    "          \n",
    "            type_to_index = {t: i for i, t in enumerate(all_types)}\n",
    "  \n",
    "            p1_types = []\n",
    "            p1_stats = []\n",
    "            for p_name in p1_pokemon_left:\n",
    "                p_data = pokemon_df[pokemon_df['name'] == p_name].iloc[0]\n",
    "                p1_types.append(p_data['types'])\n",
    "                p1_stats.append([\n",
    "                    p_data['base_hp'],\n",
    "                    p_data['base_atk'],\n",
    "                    p_data['base_def'],\n",
    "                    p_data['base_spa'],\n",
    "                    p_data['base_spd'],\n",
    "                    p_data['base_spe'],\n",
    "                ])\n",
    "            enemy_types = []\n",
    "            enemy_stats = []\n",
    "            for e_name in p2_pokemon_left:\n",
    "                e_data = pokemon_df[pokemon_df['name'] == e_name].iloc[0]\n",
    "                enemy_types.append(e_data['types'])\n",
    "                enemy_stats.append([\n",
    "                    e_data['base_hp'],\n",
    "                    e_data['base_atk'],\n",
    "                    e_data['base_def'],\n",
    "                    e_data['base_spa'],\n",
    "                    e_data['base_spd'],\n",
    "                    e_data['base_spe'],\n",
    "                ])\n",
    "                \n",
    "                # now compute the type advantage and stat advantage\n",
    "                # flatten type lists, remove \"notype\"\n",
    "                p1_all_types = [t for ts in p1_types for t in ts if t != \"notype\"]\n",
    "                p2_all_types = [t for ts in enemy_types for t in ts if t != \"notype\"]\n",
    "                # team vs team type advantage\n",
    "                p1_type_adv = compute_type_advantage(p1_all_types, p2_all_types, type_chart)\n",
    "                p2_type_adv = compute_type_advantage(p2_all_types, p1_all_types, type_chart)\n",
    "\n",
    "                type_advantage = p1_type_adv / p2_type_adv\n",
    "                \n",
    "                # convert to numpy arrays\n",
    "                p1_stats = np.array(p1_stats, dtype=float)\n",
    "                p2_stats = np.array(enemy_stats, dtype=float)\n",
    "\n",
    "                # compute mean overall stat\n",
    "                p1_avg = p1_stats.mean()\n",
    "                p2_avg = p2_stats.mean()\n",
    "\n",
    "                stat_advantage = p1_avg / p2_avg\n",
    "\n",
    "\n",
    "            return type_advantage, stat_advantage\n",
    "\n",
    "        type_advantage, stat_advantage = type_and_stat_advantages(p1_pokemon_left, p2_pokemon_left, \n",
    "                                                                                        pokemon_df, \n",
    "                                                                                        all_types)\n",
    "        \n",
    "        boost_advantage = np.mean(list(p1_stats[\"avg_boosts\"].values())) - np.mean(list(p2_stats[\"avg_boosts\"].values()))\n",
    "        \n",
    "        features = {\n",
    "            \"battle_id\": battle.get(\"battle_id\"),\n",
    "            \"hp_ratio\": p1_stats[\"total_hp_left\"] / (p2_stats[\"total_hp_left\"] + 1e-9),\n",
    "            \"p1_num_seen\": p1_stats[\"num_seen\"],\n",
    "            \"p2_num_seen\": p2_stats[\"num_seen\"],\n",
    "            \"p1_num_fainted\": p1_stats[\"num_fainted\"],\n",
    "            \"p2_num_fainted\": p2_stats[\"num_fainted\"],\n",
    "            \"num_paralyzed_diff\": p1_stats[\"num_paralyzed\"] - p2_stats[\"num_paralyzed\"],\n",
    "            \"num_frozen_diff\": p1_stats[\"num_frozen\"] - p2_stats[\"num_frozen\"],\n",
    "            \"num_psn_diff\": p1_stats[\"num_psn\"] - p2_stats[\"num_psn\"],\n",
    "            \"num_brn_diff\": p1_stats[\"num_brn\"] - p2_stats[\"num_brn\"],\n",
    "            \"num_slp_diff\": p1_stats[\"num_slp\"] - p2_stats[\"num_slp\"],\n",
    "            \"num_seen_diff\": p1_stats[\"num_seen\"] - p2_stats[\"num_seen\"],\n",
    "            \"num_fainted_diff\": p1_stats[\"num_fainted\"] - p2_stats[\"num_fainted\"],\n",
    "            \"type_advantage\": type_advantage,\n",
    "            \"stat_advantage\": stat_advantage,\n",
    "            \"boost_advantage\": boost_advantage,\n",
    "            \"stall_move_usage_diff\": stall_move_usage_diff,\n",
    "            \"boost_move_usage_diff\": boost_move_usage_diff,\n",
    "            \"switch_frequency_diff\": switch_frequency_diff,\n",
    "            \"num_setup_diff\": num_setup_diff,\n",
    "            \"has_recovery_diff\": has_recovery_diff\n",
    "        }\n",
    "\n",
    "        \n",
    "\n",
    "        feature_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(feature_list).fillna(0)\n",
    "\n",
    "print(\"Processing training data...\")\n",
    "train_df_dynamic = create_dynamic_features(train_data)\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "test_df_dynamic = create_dynamic_features(test_data)\n",
    "\n",
    "print(\"\\nTraining features preview:\")\n",
    "display(train_df_dynamic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   p1_mean_hp  p1_mean_spe  p1_mean_atk  p1_mean_def  p1_mean_spa  \\\n",
      "0  115.833333    80.000000    72.500000    63.333333   100.000000   \n",
      "1  123.333333    61.666667    72.500000    65.833333    90.000000   \n",
      "2  124.166667    65.833333    84.166667    71.666667    90.000000   \n",
      "3  121.666667    75.833333    77.500000    65.833333   103.333333   \n",
      "4  114.166667    72.500000    75.833333    79.166667    97.500000   \n",
      "\n",
      "   p1_mean_spd  p2_lead_hp  p2_lead_spe  p2_lead_atk  p2_lead_def  ...  \\\n",
      "0   100.000000          60          115           75           85  ...   \n",
      "1    90.000000          55          120           50           45  ...   \n",
      "2    90.000000         250           50            5            5  ...   \n",
      "3   103.333333          75          110          100           95  ...   \n",
      "4    97.500000          60          115           75           85  ...   \n",
      "\n",
      "   num_seen_diff  num_fainted_diff  type_advantage  stat_advantage  \\\n",
      "0              0                 0        0.923077        0.962733   \n",
      "1              0                 3        0.951613        0.946708   \n",
      "2             -1                 1        1.000000        0.950820   \n",
      "3              1                 3        1.057143        1.032558   \n",
      "4              0                 1        1.046875        1.018868   \n",
      "\n",
      "   boost_advantage  stall_move_usage_diff  boost_move_usage_diff  \\\n",
      "0         0.000000                      7                      0   \n",
      "1         0.066667                     -2                      0   \n",
      "2         0.100000                     -2                      8   \n",
      "3         0.000000                      3                      0   \n",
      "4         0.000000                     -6                      0   \n",
      "\n",
      "   switch_frequency_diff  num_setup_diff  has_recovery_diff  \n",
      "0                     -4               0                 -1  \n",
      "1                      0               0                  0  \n",
      "2                      2               1                 -1  \n",
      "3                      1               0                  0  \n",
      "4                     -2               0                  0  \n",
      "\n",
      "[5 rows x 34 columns] Index(['p1_mean_hp', 'p1_mean_spe', 'p1_mean_atk', 'p1_mean_def',\n",
      "       'p1_mean_spa', 'p1_mean_spd', 'p2_lead_hp', 'p2_lead_spe',\n",
      "       'p2_lead_atk', 'p2_lead_def', 'p2_lead_spa', 'p2_lead_spd', 'battle_id',\n",
      "       'player_won', 'hp_ratio', 'p1_num_seen', 'p2_num_seen',\n",
      "       'p1_num_fainted', 'p2_num_fainted', 'num_paralyzed_diff',\n",
      "       'num_frozen_diff', 'num_psn_diff', 'num_brn_diff', 'num_slp_diff',\n",
      "       'num_seen_diff', 'num_fainted_diff', 'type_advantage', 'stat_advantage',\n",
      "       'boost_advantage', 'stall_move_usage_diff', 'boost_move_usage_diff',\n",
      "       'switch_frequency_diff', 'num_setup_diff', 'has_recovery_diff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Combine Dynamic Features with Simple Features\n",
    "train_df_combined = pd.merge(train_df, train_df_dynamic, on=\"battle_id\", how=\"inner\")\n",
    "test_df_combined = pd.merge(test_df, test_df_dynamic, on=\"battle_id\", how=\"inner\")\n",
    "\n",
    "print(train_df_combined.head(), train_df_combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training a Baseline Model\n",
    "\n",
    "Now that we have some features, let's train a simple `LogisticRegression` model. This will give us a starting point for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T13:39:53.022400Z",
     "iopub.status.busy": "2025-10-24T13:39:53.021996Z",
     "iopub.status.idle": "2025-10-24T13:39:53.847883Z",
     "shell.execute_reply": "2025-10-24T13:39:53.847309Z",
     "shell.execute_reply.started": "2025-10-24T13:39:53.022379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature set: ['p1_mean_hp', 'p1_mean_spe', 'p1_mean_atk', 'p1_mean_def', 'p1_mean_spa', 'p1_mean_spd', 'p2_lead_hp', 'p2_lead_spe', 'p2_lead_atk', 'p2_lead_def', 'p2_lead_spa', 'p2_lead_spd', 'hp_ratio', 'p1_num_seen', 'p2_num_seen', 'p1_num_fainted', 'p2_num_fainted', 'num_paralyzed_diff', 'num_frozen_diff', 'num_psn_diff', 'num_brn_diff', 'num_slp_diff', 'num_seen_diff', 'num_fainted_diff', 'type_advantage', 'stat_advantage', 'boost_advantage', 'stall_move_usage_diff', 'boost_move_usage_diff', 'switch_frequency_diff', 'num_setup_diff', 'has_recovery_diff']\n",
      "   p1_mean_hp  p1_mean_spe  p1_mean_atk  p1_mean_def  p1_mean_spa  \\\n",
      "0  117.500000    78.333333    74.166667    61.666667    93.333333   \n",
      "1   70.166667    95.833333    95.666667    96.666667    94.166667   \n",
      "2  120.000000    61.666667    90.833333    88.333333    78.333333   \n",
      "3  114.166667    71.666667    70.000000    71.666667    97.500000   \n",
      "4  116.666667    78.333333    75.000000    65.833333    99.166667   \n",
      "\n",
      "   p1_mean_spd  p2_lead_hp  p2_lead_spe  p2_lead_atk  p2_lead_def  ...  \\\n",
      "0    93.333333          65          130           65           60  ...   \n",
      "1    94.166667          55          120           50           45  ...   \n",
      "2    78.333333          55          120           50           45  ...   \n",
      "3    97.500000         160           30          110           65  ...   \n",
      "4    99.166667          60          110           65           60  ...   \n",
      "\n",
      "   num_seen_diff  num_fainted_diff  type_advantage  stat_advantage  \\\n",
      "0              0                 4        1.000000        0.839695   \n",
      "1             -2                 1        0.948454        1.070644   \n",
      "2             -1                 1        0.992701        0.998408   \n",
      "3             -2                 0        1.092308        0.956386   \n",
      "4             -1                 2        1.138889        0.993409   \n",
      "\n",
      "   boost_advantage  stall_move_usage_diff  boost_move_usage_diff  \\\n",
      "0        -0.160000                     -5                     -4   \n",
      "1         0.000000                      2                      2   \n",
      "2        -0.066667                      6                     -6   \n",
      "3         0.026667                     14                      0   \n",
      "4         0.080000                      2                      0   \n",
      "\n",
      "   switch_frequency_diff  num_setup_diff  has_recovery_diff  \n",
      "0                      1              -1                  0  \n",
      "1                     -5               1                  0  \n",
      "2                     -3              -1                  0  \n",
      "3                      0               0                  0  \n",
      "4                      2               0                  0  \n",
      "\n",
      "[5 rows x 33 columns] Index(['p1_mean_hp', 'p1_mean_spe', 'p1_mean_atk', 'p1_mean_def',\n",
      "       'p1_mean_spa', 'p1_mean_spd', 'p2_lead_hp', 'p2_lead_spe',\n",
      "       'p2_lead_atk', 'p2_lead_def', 'p2_lead_spa', 'p2_lead_spd', 'battle_id',\n",
      "       'hp_ratio', 'p1_num_seen', 'p2_num_seen', 'p1_num_fainted',\n",
      "       'p2_num_fainted', 'num_paralyzed_diff', 'num_frozen_diff',\n",
      "       'num_psn_diff', 'num_brn_diff', 'num_slp_diff', 'num_seen_diff',\n",
      "       'num_fainted_diff', 'type_advantage', 'stat_advantage',\n",
      "       'boost_advantage', 'stall_move_usage_diff', 'boost_move_usage_diff',\n",
      "       'switch_frequency_diff', 'num_setup_diff', 'has_recovery_diff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "features = [col for col in train_df_combined.columns if col not in ['battle_id', \n",
    "                                                                    'player_won'\n",
    "                                                                    ]]\n",
    "print(\"Final feature set:\", features)\n",
    "print(test_df_combined.head(), test_df_combined.columns)\n",
    "X_train = train_df_combined[features]\n",
    "y_train = train_df_combined['player_won']\n",
    "X_test = test_df_combined[features]\n",
    "# Maybe compute the type and stat advantages only on the pokemon that are alive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from xgboost) (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from lightgbm) (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from lightgbm) (1.15.2)\n",
      "Requirement already satisfied: catboost in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from catboost) (3.10.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from catboost) (2.2.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from catboost) (1.15.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from catboost) (6.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from matplotlib->catboost) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from matplotlib->catboost) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from plotly->catboost) (2.10.1)\n",
      "Requirement already satisfied: optuna in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from optuna) (1.17.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from optuna) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from optuna) (2.0.44)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\pier1\\anaconda3\\envs\\or\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install scikit-learn\n",
    "!pip install lightgbm\n",
    "!pip install catboost\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,     # 20% validation set\n",
    "    random_state=42,   # makes it reproducible\n",
    "    stratify=y_train         # keeps class balance\n",
    ")\n",
    "\n",
    "# --- Define objective function ---\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical(\"model\", [\"LogReg\", \"RandomForest\", \"XGBoost\", \"LightGBM\", \"CatBoost\", \"NeuralNet\"])\n",
    "    \n",
    "    if model_name == \"LogReg\":\n",
    "        C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
    "        model = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                          (\"model\", LogisticRegression(C=C, penalty=\"l2\", solver=\"lbfgs\", max_iter=1000))])\n",
    "    \n",
    "    elif model_name == \"RandomForest\":\n",
    "        n_estimators = trial.suggest_int(\"rf_n_estimators\", 20, 200)\n",
    "        max_depth = trial.suggest_int(\"rf_max_depth\", 3, 20)\n",
    "        min_samples_split = trial.suggest_int(\"rf_min_samples_split\", 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int(\"rf_min_samples_leaf\", 1, 5)\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                       max_depth=max_depth,\n",
    "                                       min_samples_split=min_samples_split,\n",
    "                                       min_samples_leaf=min_samples_leaf,\n",
    "                                       random_state=42)\n",
    "    \n",
    "    elif model_name == \"XGBoost\":\n",
    "        n_estimators = trial.suggest_int(\"xgb_n_estimators\", 20, 200)\n",
    "        max_depth = trial.suggest_int(\"xgb_max_depth\", 3, 10)\n",
    "        learning_rate = trial.suggest_loguniform(\"xgb_lr\", 0.01, 0.3)\n",
    "        subsample = trial.suggest_float(\"xgb_subsample\", 0.6, 1.0)\n",
    "        model = xgb.XGBClassifier(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  subsample=subsample,\n",
    "                                  use_label_encoder=False,\n",
    "                                  eval_metric=\"logloss\",\n",
    "                                  random_state=42)\n",
    "    \n",
    "    elif model_name == \"LightGBM\":\n",
    "        n_estimators = trial.suggest_int(\"lgb_n_estimators\", 20, 200)\n",
    "        num_leaves = trial.suggest_int(\"lgb_num_leaves\", 5, 100)\n",
    "        learning_rate = trial.suggest_loguniform(\"lgb_lr\", 0.01, 0.3)\n",
    "        colsample_bytree = trial.suggest_float(\"lgb_colsample\", 0.6, 1.0)\n",
    "        model = lgb.LGBMClassifier(n_estimators=n_estimators,\n",
    "                                   num_leaves=num_leaves,\n",
    "                                   learning_rate=learning_rate,\n",
    "                                   colsample_bytree=colsample_bytree,\n",
    "                                   random_state=42)\n",
    "    \n",
    "    elif model_name == \"CatBoost\":\n",
    "        iterations = trial.suggest_int(\"cat_iterations\", 100, 500)\n",
    "        depth = trial.suggest_int(\"cat_depth\", 3, 10)\n",
    "        learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
    "        model = CatBoostClassifier(iterations=iterations,\n",
    "                                   depth=depth,\n",
    "                                   learning_rate=learning_rate,\n",
    "                                   verbose=False,\n",
    "                                   random_state=42)\n",
    "    \n",
    "    elif model_name == \"NeuralNet\":\n",
    "        hidden_layer_sizes = trial.suggest_categorical(\"nn_hidden\", [(8, 16, 32), (8, 16, 32)])\n",
    "        activation = trial.suggest_categorical(\"nn_activation\", [\"relu\", \"tanh\"])\n",
    "        alpha = trial.suggest_loguniform(\"nn_alpha\", 1e-4, 1e-2)\n",
    "        learning_rate_init = trial.suggest_loguniform(\"nn_lr\", 1e-4, 5e-3)\n",
    "        model = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                          (\"model\", MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                                  activation=activation,\n",
    "                                                  alpha=alpha,\n",
    "                                                  learning_rate_init=learning_rate_init,\n",
    "                                                  learning_rate='adaptive',\n",
    "                                                  max_iter=500,\n",
    "                                                  random_state=42))])\n",
    "        \n",
    "    score = cross_val_score(model, X_train, y_train, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 11:08:32,762] A new study created in memory with name: no-name-e44fee99-be76-420f-8edf-d5ada1218937\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:08:32,811] Trial 0 finished with value: 0.8399999999999999 and parameters: {'model': 'LogReg', 'logreg_C': 0.01981596456104395}. Best is trial 0 with value: 0.8399999999999999.\n",
      "[I 2025-11-13 11:08:33,077] Trial 1 finished with value: 0.8246249999999999 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 30, 'rf_max_depth': 12, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 1}. Best is trial 0 with value: 0.8399999999999999.\n",
      "c:\\Users\\pier1\\anaconda3\\envs\\OR\\Lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (8, 16, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform(\"nn_alpha\", 1e-4, 1e-2)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform(\"nn_lr\", 1e-4, 5e-3)\n",
      "[I 2025-11-13 11:09:00,149] Trial 2 finished with value: 0.827125 and parameters: {'model': 'NeuralNet', 'nn_hidden': (8, 16, 32), 'nn_activation': 'tanh', 'nn_alpha': 0.004975401965858595, 'nn_lr': 0.0006685269619201582}. Best is trial 0 with value: 0.8399999999999999.\n",
      "c:\\Users\\pier1\\anaconda3\\envs\\OR\\Lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (8, 16, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform(\"nn_alpha\", 1e-4, 1e-2)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform(\"nn_lr\", 1e-4, 5e-3)\n",
      "[I 2025-11-13 11:09:03,933] Trial 3 finished with value: 0.8163750000000001 and parameters: {'model': 'NeuralNet', 'nn_hidden': (8, 16, 32), 'nn_activation': 'relu', 'nn_alpha': 0.0004884508769235218, 'nn_lr': 0.003622573322721962}. Best is trial 0 with value: 0.8399999999999999.\n",
      "[I 2025-11-13 11:09:04,499] Trial 4 finished with value: 0.827125 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 65, 'rf_max_depth': 12, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 5}. Best is trial 0 with value: 0.8399999999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"xgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:05,353] Trial 5 finished with value: 0.8342499999999999 and parameters: {'model': 'XGBoost', 'xgb_n_estimators': 176, 'xgb_max_depth': 10, 'xgb_lr': 0.06997922630838974, 'xgb_subsample': 0.6965468319054787}. Best is trial 0 with value: 0.8399999999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:05,402] Trial 6 finished with value: 0.8398749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 0.02012689763510759}. Best is trial 0 with value: 0.8399999999999999.\n",
      "[I 2025-11-13 11:09:07,089] Trial 7 finished with value: 0.830875 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 188, 'rf_max_depth': 17, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 2}. Best is trial 0 with value: 0.8399999999999999.\n",
      "[I 2025-11-13 11:09:08,635] Trial 8 finished with value: 0.829125 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 198, 'rf_max_depth': 13, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 4}. Best is trial 0 with value: 0.8399999999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:11,934] Trial 9 finished with value: 0.8328749999999999 and parameters: {'model': 'CatBoost', 'cat_iterations': 428, 'cat_depth': 8, 'cat_learning_rate': 0.11688185515883728}. Best is trial 0 with value: 0.8399999999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:12,004] Trial 10 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 5.830422694340808}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:12,065] Trial 11 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 8.133488513777003}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"lgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:14,324] Trial 12 finished with value: 0.8321249999999999 and parameters: {'model': 'LightGBM', 'lgb_n_estimators': 163, 'lgb_num_leaves': 98, 'lgb_lr': 0.014163982390228919, 'lgb_colsample': 0.6940084028326989}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:14,388] Trial 13 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 9.947606210662608}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:14,443] Trial 14 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 8.050058065255424}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:14,493] Trial 15 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 1.5427401873648214}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"lgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:14,630] Trial 16 finished with value: 0.8366250000000001 and parameters: {'model': 'LightGBM', 'lgb_n_estimators': 50, 'lgb_num_leaves': 8, 'lgb_lr': 0.29124342430647643, 'lgb_colsample': 0.9685252646848319}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:15,079] Trial 17 finished with value: 0.8248750000000001 and parameters: {'model': 'CatBoost', 'cat_iterations': 132, 'cat_depth': 3, 'cat_learning_rate': 0.018293571981438512}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"xgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:15,198] Trial 18 finished with value: 0.7975 and parameters: {'model': 'XGBoost', 'xgb_n_estimators': 30, 'xgb_max_depth': 3, 'xgb_lr': 0.011059065856896502, 'xgb_subsample': 0.9954637110741971}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:15,250] Trial 19 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 0.8716556996745046}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:15,311] Trial 20 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 2.397528029869035}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:15,374] Trial 21 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 8.312964419311447}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:15,434] Trial 22 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 8.730677120613112}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:15,495] Trial 23 finished with value: 0.8405000000000001 and parameters: {'model': 'LogReg', 'logreg_C': 0.15115221584951172}. Best is trial 10 with value: 0.8407500000000001.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:15,557] Trial 24 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.1273680951665312}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:15,640] Trial 25 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 2.0961771265030515}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"lgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:17,711] Trial 26 finished with value: 0.8332499999999999 and parameters: {'model': 'LightGBM', 'lgb_n_estimators': 198, 'lgb_num_leaves': 50, 'lgb_lr': 0.13664580758928555, 'lgb_colsample': 0.6074476243964034}. Best is trial 24 with value: 0.8408749999999999.\n",
      "c:\\Users\\pier1\\anaconda3\\envs\\OR\\Lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (8, 16, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform(\"nn_alpha\", 1e-4, 1e-2)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform(\"nn_lr\", 1e-4, 5e-3)\n",
      "[I 2025-11-13 11:09:22,718] Trial 27 finished with value: 0.83575 and parameters: {'model': 'NeuralNet', 'nn_hidden': (8, 16, 32), 'nn_activation': 'relu', 'nn_alpha': 0.00011750774317999722, 'nn_lr': 0.00011476167655366774}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"xgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:22,928] Trial 28 finished with value: 0.8264999999999999 and parameters: {'model': 'XGBoost', 'xgb_n_estimators': 73, 'xgb_max_depth': 6, 'xgb_lr': 0.25361055286807405, 'xgb_subsample': 0.6043723642465997}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:22,992] Trial 29 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.2676251375959136}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:26,691] Trial 30 finished with value: 0.8307499999999999 and parameters: {'model': 'CatBoost', 'cat_iterations': 103, 'cat_depth': 10, 'cat_learning_rate': 0.22232772226124076}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:26,766] Trial 31 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.236451322905297}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:26,830] Trial 32 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.069861551742282}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:26,894] Trial 33 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 0.46670628964821165}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:26,958] Trial 34 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.1101033376754983}. Best is trial 24 with value: 0.8408749999999999.\n",
      "c:\\Users\\pier1\\anaconda3\\envs\\OR\\Lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (8, 16, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform(\"nn_alpha\", 1e-4, 1e-2)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform(\"nn_lr\", 1e-4, 5e-3)\n",
      "[I 2025-11-13 11:09:33,873] Trial 35 finished with value: 0.7925000000000001 and parameters: {'model': 'NeuralNet', 'nn_hidden': (8, 16, 32), 'nn_activation': 'tanh', 'nn_alpha': 0.005228803726037197, 'nn_lr': 0.004555403760661352}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:33,932] Trial 36 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 0.9916206382518349}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:33,982] Trial 37 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.4528577649838463}. Best is trial 24 with value: 0.8408749999999999.\n",
      "[I 2025-11-13 11:09:34,519] Trial 38 finished with value: 0.80625 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 123, 'rf_max_depth': 4, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 3}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"xgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:36,334] Trial 39 finished with value: 0.83025 and parameters: {'model': 'XGBoost', 'xgb_n_estimators': 193, 'xgb_max_depth': 10, 'xgb_lr': 0.013146672215071691, 'xgb_subsample': 0.8975787340950302}. Best is trial 24 with value: 0.8408749999999999.\n",
      "c:\\Users\\pier1\\anaconda3\\envs\\OR\\Lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (8, 16, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform(\"nn_alpha\", 1e-4, 1e-2)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform(\"nn_lr\", 1e-4, 5e-3)\n",
      "[I 2025-11-13 11:09:41,017] Trial 40 finished with value: 0.8355 and parameters: {'model': 'NeuralNet', 'nn_hidden': (8, 16, 32), 'nn_activation': 'relu', 'nn_alpha': 0.0009031606133754191, 'nn_lr': 0.00010427109290658263}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:41,068] Trial 41 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.4217303999599773}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:41,116] Trial 42 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.7071843204539667}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:41,165] Trial 43 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 1.5195304192275658}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:41,213] Trial 44 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 4.033658919692352}. Best is trial 24 with value: 0.8408749999999999.\n",
      "[I 2025-11-13 11:09:41,680] Trial 45 finished with value: 0.8001250000000001 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 128, 'rf_max_depth': 3, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 5}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:41,732] Trial 46 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 0.9043840825104262}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:43,649] Trial 47 finished with value: 0.8373750000000001 and parameters: {'model': 'CatBoost', 'cat_iterations': 498, 'cat_depth': 3, 'cat_learning_rate': 0.011546005314593674}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:43,722] Trial 48 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 0.2282183081152057}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"lgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:44,200] Trial 49 finished with value: 0.81775 and parameters: {'model': 'LightGBM', 'lgb_n_estimators': 24, 'lgb_num_leaves': 97, 'lgb_lr': 0.010811593923156079, 'lgb_colsample': 0.9251099280659929}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:44,285] Trial 50 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 2.114040154476498}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:44,352] Trial 51 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 4.124681055790239}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:44,413] Trial 52 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.0475106399272245}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:44,463] Trial 53 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 4.545712135739563}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:44,514] Trial 54 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 1.5576634386417703}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:44,575] Trial 55 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 2.524088415980854}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:44,626] Trial 56 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 5.637492162960293}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"xgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:44,816] Trial 57 finished with value: 0.83475 and parameters: {'model': 'XGBoost', 'xgb_n_estimators': 124, 'xgb_max_depth': 3, 'xgb_lr': 0.28856017996423367, 'xgb_subsample': 0.7775634977884955}. Best is trial 24 with value: 0.8408749999999999.\n",
      "[I 2025-11-13 11:09:45,765] Trial 58 finished with value: 0.826375 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 74, 'rf_max_depth': 20, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 1}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:45,827] Trial 59 finished with value: 0.8398749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 0.02805569980900422}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"lgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:46,120] Trial 60 finished with value: 0.8338749999999999 and parameters: {'model': 'LightGBM', 'lgb_n_estimators': 109, 'lgb_num_leaves': 5, 'lgb_lr': 0.03989908004311432, 'lgb_colsample': 0.8056274833618114}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:46,205] Trial 61 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 2.959833252186849}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:46,270] Trial 62 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 5.26315512363738}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:46,342] Trial 63 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.1221459177888256}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:09:46,405] Trial 64 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 1.5193421255909483}. Best is trial 24 with value: 0.8408749999999999.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:48,349] Trial 65 finished with value: 0.841 and parameters: {'model': 'CatBoost', 'cat_iterations': 296, 'cat_depth': 6, 'cat_learning_rate': 0.03939158984660228}. Best is trial 65 with value: 0.841.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:50,397] Trial 66 finished with value: 0.8408749999999999 and parameters: {'model': 'CatBoost', 'cat_iterations': 306, 'cat_depth': 6, 'cat_learning_rate': 0.04161132096848484}. Best is trial 65 with value: 0.841.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:52,283] Trial 67 finished with value: 0.8402499999999999 and parameters: {'model': 'CatBoost', 'cat_iterations': 283, 'cat_depth': 6, 'cat_learning_rate': 0.04019505698382982}. Best is trial 65 with value: 0.841.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:53,778] Trial 68 finished with value: 0.841625 and parameters: {'model': 'CatBoost', 'cat_iterations': 275, 'cat_depth': 5, 'cat_learning_rate': 0.08029789776807468}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:55,624] Trial 69 finished with value: 0.83775 and parameters: {'model': 'CatBoost', 'cat_iterations': 277, 'cat_depth': 6, 'cat_learning_rate': 0.08625218026979645}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:09:56,810] Trial 70 finished with value: 0.8407499999999999 and parameters: {'model': 'CatBoost', 'cat_iterations': 214, 'cat_depth': 5, 'cat_learning_rate': 0.06421157385406277}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:00,946] Trial 71 finished with value: 0.8393750000000001 and parameters: {'model': 'CatBoost', 'cat_iterations': 363, 'cat_depth': 8, 'cat_learning_rate': 0.026735667176979564}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:01,965] Trial 72 finished with value: 0.83775 and parameters: {'model': 'CatBoost', 'cat_iterations': 210, 'cat_depth': 4, 'cat_learning_rate': 0.1639430608908561}. Best is trial 68 with value: 0.841625.\n",
      "c:\\Users\\pier1\\anaconda3\\envs\\OR\\Lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (8, 16, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform(\"nn_alpha\", 1e-4, 1e-2)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform(\"nn_lr\", 1e-4, 5e-3)\n",
      "[I 2025-11-13 11:10:10,712] Trial 73 finished with value: 0.827 and parameters: {'model': 'NeuralNet', 'nn_hidden': (8, 16, 32), 'nn_activation': 'tanh', 'nn_alpha': 0.00011180973192092289, 'nn_lr': 0.0006626974346521493}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:13,790] Trial 74 finished with value: 0.8393750000000001 and parameters: {'model': 'CatBoost', 'cat_iterations': 359, 'cat_depth': 7, 'cat_learning_rate': 0.06396624938700979}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:15,099] Trial 75 finished with value: 0.8403750000000001 and parameters: {'model': 'CatBoost', 'cat_iterations': 222, 'cat_depth': 5, 'cat_learning_rate': 0.02630315472932233}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"xgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:15,639] Trial 76 finished with value: 0.836875 and parameters: {'model': 'XGBoost', 'xgb_n_estimators': 125, 'xgb_max_depth': 7, 'xgb_lr': 0.043698467711168226, 'xgb_subsample': 0.8619701415890014}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:15,701] Trial 77 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 0.6120290006891221}. Best is trial 68 with value: 0.841625.\n",
      "[I 2025-11-13 11:10:16,783] Trial 78 finished with value: 0.8210000000000001 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 155, 'rf_max_depth': 7, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 3}. Best is trial 68 with value: 0.841625.\n",
      "c:\\Users\\pier1\\anaconda3\\envs\\OR\\Lib\\site-packages\\optuna\\distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (8, 16, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform(\"nn_alpha\", 1e-4, 1e-2)\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform(\"nn_lr\", 1e-4, 5e-3)\n",
      "[I 2025-11-13 11:10:23,999] Trial 79 finished with value: 0.8243750000000001 and parameters: {'model': 'NeuralNet', 'nn_hidden': (8, 16, 32), 'nn_activation': 'relu', 'nn_alpha': 0.008876655058442795, 'nn_lr': 0.00143603029476274}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"lgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:24,887] Trial 80 finished with value: 0.8324999999999999 and parameters: {'model': 'LightGBM', 'lgb_n_estimators': 99, 'lgb_num_leaves': 42, 'lgb_lr': 0.04720591585273341, 'lgb_colsample': 0.8284576945718821}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:24,967] Trial 81 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 6.114891255471659}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:25,035] Trial 82 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 1.925527643122788}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:25,097] Trial 83 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 6.089271190740678}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:25,158] Trial 84 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 1.1438429536500456}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:25,223] Trial 85 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 2.958130711730901}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:25,275] Trial 86 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 4.711867464575441}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:27,098] Trial 87 finished with value: 0.8391250000000001 and parameters: {'model': 'CatBoost', 'cat_iterations': 350, 'cat_depth': 5, 'cat_learning_rate': 0.1276224126426293}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,171] Trial 88 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 7.072657168451257}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,235] Trial 89 finished with value: 0.8398749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 0.05041177377752729}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,299] Trial 90 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 9.941683363010522}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,362] Trial 91 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.6717523402514525}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,424] Trial 92 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 2.031552853537593}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,486] Trial 93 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 3.4822122169421523}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,548] Trial 94 finished with value: 0.8407500000000001 and parameters: {'model': 'LogReg', 'logreg_C': 2.5477476833281103}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,611] Trial 95 finished with value: 0.8408749999999999 and parameters: {'model': 'LogReg', 'logreg_C': 4.028592447864877}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"xgb_lr\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:27,748] Trial 96 finished with value: 0.8288749999999998 and parameters: {'model': 'XGBoost', 'xgb_n_estimators': 25, 'xgb_max_depth': 6, 'xgb_lr': 0.07376417434757596, 'xgb_subsample': 0.9908066797715954}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"logreg_C\", 0.01, 10)\n",
      "[I 2025-11-13 11:10:27,812] Trial 97 finished with value: 0.840625 and parameters: {'model': 'LogReg', 'logreg_C': 1.2806482186649768}. Best is trial 68 with value: 0.841625.\n",
      "C:\\Users\\pier1\\AppData\\Local\\Temp\\ipykernel_22032\\4220451761.py:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"cat_learning_rate\", 0.01, 0.3)\n",
      "[I 2025-11-13 11:10:30,086] Trial 98 finished with value: 0.827 and parameters: {'model': 'CatBoost', 'cat_iterations': 173, 'cat_depth': 8, 'cat_learning_rate': 0.29522922215589203}. Best is trial 68 with value: 0.841625.\n",
      "[I 2025-11-13 11:10:30,305] Trial 99 finished with value: 0.81875 and parameters: {'model': 'RandomForest', 'rf_n_estimators': 21, 'rf_max_depth': 7, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 2}. Best is trial 68 with value: 0.841625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model and params:\n",
      "{'model': 'CatBoost', 'cat_iterations': 275, 'cat_depth': 5, 'cat_learning_rate': 0.08029789776807468}\n",
      "Best CV accuracy: 0.841625\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best model and params:\")\n",
    "print(study.best_trial.params)\n",
    "print(\"Best CV accuracy:\", study.best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'CatBoost', 'cat_iterations': 275, 'cat_depth': 5, 'cat_learning_rate': 0.08029789776807468}\n",
      "Training best model: CatBoost\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x20896bcc7d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "print(best_params)\n",
    "\n",
    "print(\"Training best model:\", best_params[\"model\"])\n",
    "if best_params[\"model\"] == \"logreg\":\n",
    "    model = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                      (\"model\", LogisticRegression(**best_params, penalty=\"l2\", solver=\"lbfgs\", max_iter=1000))])\n",
    "elif best_params[\"model\"] == \"randomforest\":\n",
    "    model = RandomForestClassifier(**best_params, random_state=42)\n",
    "elif best_params[\"model\"] == \"XGBoost\":\n",
    "    model = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "elif best_params[\"model\"] == \"LightGBM\":\n",
    "    model = lgb.LGBMClassifier(num_leaves=best_params['lgb_num_leaves'],\n",
    "                                n_estimators=best_params['lgb_n_estimators'],\n",
    "                                learning_rate=best_params['lgb_lr'],\n",
    "                                colsample_bytree=best_params['lgb_colsample'])\n",
    "elif best_params[\"model\"] == \"CatBoost\":\n",
    "    model = CatBoostClassifier(iterations=best_params['cat_iterations'], \n",
    "                               depth=best_params['cat_depth'], \n",
    "                               learning_rate=best_params['cat_learning_rate'], verbose=False, random_state=42)\n",
    "elif best_params[\"model\"] == \"neuralnet\":\n",
    "    model = Pipeline([(\"scaler\", StandardScaler()), (\"model\", MLPClassifier(**best_params, max_iter=500, random_state=42))])\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8450\n",
      "\n",
      "Confusion Matrix:\n",
      "[[865 135]\n",
      " [175 825]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating the Submission File\n",
    "\n",
    "The competition requires a `.csv` file with two columns: `battle_id` and `player_won`. Let's use our trained model to make predictions on the test set and format them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T13:40:01.862380Z",
     "iopub.status.busy": "2025-10-24T13:40:01.861941Z",
     "iopub.status.idle": "2025-10-24T13:40:01.884654Z",
     "shell.execute_reply": "2025-10-24T13:40:01.883092Z",
     "shell.execute_reply.started": "2025-10-24T13:40:01.862364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on the test set...\n",
      "\n",
      "'submission.csv' file created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won\n",
       "0          0           0\n",
       "1          1           1\n",
       "2          2           1\n",
       "3          3           1\n",
       "4          4           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "print(\"Generating predictions on the test set...\")\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'],\n",
    "    'player_won': test_predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a .csv file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\n'submission.csv' file created successfully!\")\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submitting Your Results\n",
    "\n",
    "Once you have generated your `submission.csv` file, there are two primary ways to submit it to the competition.\n",
    "\n",
    "---\n",
    "\n",
    "#### Method A: Submitting Directly from the Notebook\n",
    "\n",
    "This is the standard method for code competitions. It ensures that your submission is linked to the code that produced it, which is crucial for reproducibility.\n",
    "\n",
    "1.  **Save Your Work:** Click the **\"Save Version\"** button in the top-right corner of the notebook editor.\n",
    "2.  **Run the Notebook:** In the pop-up window, select **\"Save & Run All (Commit)\"** and then click the **\"Save\"** button. This will run your entire notebook from top to bottom and save the output, including your `submission.csv` file.\n",
    "3.  **Go to the Viewer:** Once the save process is complete, navigate to the notebook viewer page. \n",
    "4.  **Submit to Competition:** In the viewer, find the **\"Submit to Competition\"** section. This is usually located in the header of the output section or in the vertical \"...\" menu on the right side of the page. Clicking the **Submit** button this will submit your generated `submission.csv` file.\n",
    "\n",
    "After submitting, you will see your score in the **\"Submit to Competition\"** section or in the [Public Leaderboard](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?).\n",
    "\n",
    "---\n",
    "\n",
    "#### Method B: Manual Upload\n",
    "\n",
    "You can also generate your predictions and submission file using any environment you prefer (this notebook, Google Colab, or your local machine).\n",
    "\n",
    "1.  **Generate the `submission.csv` file** using your model.\n",
    "2.  **Download the file** to your computer.\n",
    "3.  **Navigate to the [Leaderboard Page](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?)** and click on the **\"Submit Predictions\"** button.\n",
    "4.  **Upload Your File:** Drag and drop or select your `submission.csv` file to upload it.\n",
    "\n",
    "This method is quick, but keep in mind that for the final evaluation, you might be required to provide the code that generated your submission.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13033998,
     "sourceId": 107555,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "OR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
